{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea63b96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # this reads .env and injects into os.environ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72484f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ebdc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 1. Load environment (for OPENAI_API_KEY, optional DB_URL override)\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Configuration\n",
    "DB_URL    = os.getenv(\n",
    "    \"DB_URL\",\n",
    "    \"postgresql+psycopg2://devuser:devpassword@localhost:5433/devdb\"\n",
    ")\n",
    "MODEL_STR = os.getenv(\"OPENAI_MODEL\", \"openai:gpt-4o\")\n",
    "\n",
    "\n",
    "# 3. Global storage variable for detected columns\n",
    "classification_columns: list[str] = []\n",
    "\n",
    "# 4. Detection logic: read table, return column names\n",
    "\n",
    "def detect_classification_columns(table_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Load `table_name` into a DataFrame and return a list of columns\n",
    "    that are not IDs (col=='id' or ending '_id') and not numeric.\n",
    "    Also updates global `classification_columns`.\n",
    "    \"\"\"\n",
    "    global classification_columns\n",
    "    engine = create_engine(DB_URL)\n",
    "    df = pd.read_sql_table(table_name, engine)\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        lc = col.lower()\n",
    "        if lc == \"id\" or lc.endswith(\"_id\"):\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            continue\n",
    "        cols.append(col)\n",
    "    classification_columns = cols\n",
    "    return cols\n",
    "\n",
    "# 5. Wrap detection as a LangChain Tool\n",
    "detect_tool = Tool(\n",
    "    name=\"detect_classification_columns\",\n",
    "    func=detect_classification_columns,\n",
    "    description=(\n",
    "        \"Given a Postgres table name, return non-ID, non-numeric columns \"\n",
    "        \"for classification and store them in `classification_columns`.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 6. Initialize LLM for tool-binding\n",
    "tt_model = init_chat_model(MODEL_STR, temperature=0)\n",
    "\n",
    "# 7. Create the React agent\n",
    "agent = create_react_agent(\n",
    "    model=tt_model,\n",
    "    tools=[detect_tool],\n",
    "    prompt=(\n",
    "        \"You are an agent that receives a SQL table name, detects which columns \"\n",
    "        \"are useful for classification, and stores them in the global variable.\"\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613f6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Detecting classification columns for table: nodes\n",
      "\n",
      "Agent response:\n",
      " {'messages': [HumanMessage(content='nodes', additional_kwargs={}, response_metadata={}, id='aea745c0-921f-4843-a21e-bd6bf50db1b0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hp2jFh2WDWft4DZ3QvPeJCqz', 'function': {'arguments': '{\"__arg1\":\"nodes\"}', 'name': 'detect_classification_columns'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 99, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BVfU1x9xZUuIIlq6eata1K7gAAljU', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0d133cd7-e497-45d2-85ac-5ac574612fd1-0', tool_calls=[{'name': 'detect_classification_columns', 'args': {'__arg1': 'nodes'}, 'id': 'call_hp2jFh2WDWft4DZ3QvPeJCqz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 99, 'output_tokens': 19, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[\"type\", \"tags\"]', name='detect_classification_columns', id='3d94d8a3-59eb-41c8-b4e5-46f67d835e89', tool_call_id='call_hp2jFh2WDWft4DZ3QvPeJCqz'), AIMessage(content='The useful columns for classification in the \"nodes\" table are \"type\" and \"tags\".', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 133, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'id': 'chatcmpl-BVfU89si4yFtcz3O9AV7ssxNoHDBA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--71b5035a-eb61-428e-951b-26e0e96c9141-0', usage_metadata={'input_tokens': 133, 'output_tokens': 21, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]} \n",
      "\n",
      "Detected classification columns: ['type', 'tags']\n"
     ]
    }
   ],
   "source": [
    "table_name = \"nodes\"\n",
    "print(f\"\\n▶ Detecting classification columns for table: {table_name}\\n\")\n",
    "\n",
    "# Agent invocation will call our detect_tool\n",
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": table_name}]})\n",
    "print(\"Agent response:\\n\", response, \"\\n\")\n",
    "\n",
    "# classification_columns global now holds the detected columns\n",
    "print(\"Detected classification columns:\", classification_columns)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60710654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mihajlokruc/Developer/hackathon-agi/north-start-agi-hackathon/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import json, pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import hdbscan\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "\n",
    "def cluster_hdbscan_gemini(\n",
    "    df: pd.DataFrame,\n",
    "    columns: List[str],\n",
    "    min_cluster_size: int = 15,\n",
    "    min_samples: int | None = None,\n",
    "    metric: str = \"euclidean\",\n",
    "    model_name: str = \"models/embedding-001\"   # Gemini embedding model\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a 'cluster_label' column using HDBSCAN on Gemini embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Input data.\n",
    "    columns : List[str]\n",
    "        Columns to concatenate & embed.\n",
    "    min_cluster_size : int\n",
    "        HDBSCAN `min_cluster_size` (default 15).\n",
    "    min_samples : int | None\n",
    "        HDBSCAN `min_samples`; if None, falls back to `min_cluster_size`.\n",
    "    metric : str\n",
    "        Distance metric for HDBSCAN.  With ℓ2‑normalised vectors, use 'euclidean'.\n",
    "    model_name : str\n",
    "        Gemini embedding model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Copy of `df` with new integer column `cluster_label`\n",
    "        (‑1 means noise/outlier).\n",
    "    \"\"\"\n",
    "\n",
    "    # ── 1) Row‑text serialization (flatten JSON) ───────────────────────────\n",
    "    def _ser(v):\n",
    "        if isinstance(v, str):\n",
    "            try: v = json.loads(v)\n",
    "            except: return v\n",
    "        if isinstance(v, dict):\n",
    "            return \"{\" + \", \".join(\n",
    "                f\"{k}={json.dumps(v[k], sort_keys=True)}\" for k in sorted(v)\n",
    "            ) + \"}\"\n",
    "        return str(v)\n",
    "\n",
    "    texts = (\n",
    "        df[columns]\n",
    "        .applymap(_ser)\n",
    "        .agg(\" | \".join, axis=1)\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # ── 2) Gemini embeddings  ──────────────────────────────────────────────\n",
    "    embedder = GoogleGenerativeAIEmbeddings(\n",
    "        model=model_name,\n",
    "        task_type=\"retrieval_document\"     # recommended for doc‑level embeddings\n",
    "    )\n",
    "    embeddings = np.array(embedder.embed_documents(texts))\n",
    "    embeddings = normalize(embeddings)    # so 'euclidean' ≈ cosine\n",
    "\n",
    "    # ── 3) HDBSCAN clustering ──────────────────────────────────────────────\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=min_samples,\n",
    "        metric=metric,\n",
    "        prediction_data=False,\n",
    "    ).fit(embeddings)\n",
    "\n",
    "    # ── 4) Attach labels & return ──────────────────────────────────────────\n",
    "    df_out = df.copy()\n",
    "    df_out[\"cluster_label\"] = clusterer.labels_   # ‑1 = noise\n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687565c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(sample_size=1000, table_name=\"nodes\"):\n",
    "    engine = create_engine(DB_URL)\n",
    "    q = f\"SELECT * FROM {table_name} LIMIT {sample_size}\"\n",
    "    df = pd.read_sql(q, engine)\n",
    "    return df\n",
    "\n",
    "sample_size = 1000\n",
    "df = get_records(sample_size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf6af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xb/kjyjn5kx61950xxgm7klgb800000gn/T/ipykernel_68987/3443067475.py:54: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(_ser)\n",
      "/Users/mihajlokruc/Developer/hackathon-agi/north-start-agi-hackathon/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/mihajlokruc/Developer/hackathon-agi/north-start-agi-hackathon/.venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_label\n",
      " 2    784\n",
      " 3    102\n",
      " 1     63\n",
      " 0     31\n",
      "-1     20\n",
      "Name: count, dtype: int64\n",
      "       id  type tags        lat       lon  cluster_label\n",
      "0  123379  node   {}  51.200308  4.377739              2\n",
      "1  123380  node   {}  51.199611  4.380116              2\n",
      "2  123381  node   {}  51.199706  4.381602              2\n",
      "3  123382  node   {}  51.199627  4.383552              2\n",
      "4  123383  node   {}  51.199074  4.384953              2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clustered = cluster_hdbscan_gemini(\n",
    "    df,\n",
    "    columns=classification_columns,      # columns to embed\n",
    "    min_cluster_size=20\n",
    ")\n",
    "print(clustered[\"cluster_label\"].value_counts())\n",
    "print(clustered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3222fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Dict, Any\n",
    "import json, random\n",
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI  # Gemini chat\n",
    "\n",
    "# ---------------- helper to stringify selected cols ----------------\n",
    "def _row_text(row: pd.Series, cols: List[str]) -> str:\n",
    "    parts = []\n",
    "    for c in cols:\n",
    "        val = row[c]\n",
    "        if isinstance(val, dict):\n",
    "            val = json.dumps(val, sort_keys=True)\n",
    "        parts.append(f\"{c}={val}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "# ---------------- main routine -------------------------------------\n",
    "def name_clusters_via_llm(\n",
    "    df: pd.DataFrame,\n",
    "    cluster_col: str,\n",
    "    text_cols: List[str],\n",
    "    llm=None,\n",
    "    sample_per_cluster: int = 1_000,\n",
    ") -> tuple[pd.DataFrame, Dict[int, str]]:\n",
    "    \"\"\"\n",
    "    Adds a 'generated_category' column by LLM‑naming each cluster.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_out : DataFrame   (copy with new column)\n",
    "    mapping : {cluster_label: generated_name}\n",
    "    \"\"\"\n",
    "    llm = gemini\n",
    "    mapping: Dict[int, str] = {}\n",
    "\n",
    "    for label, sub in df.groupby(cluster_col):\n",
    "        if label == -1:               # treat noise separately\n",
    "            mapping[label] = \"noise\"\n",
    "            continue\n",
    "\n",
    "        # take up to N rows for prompt\n",
    "        sub_sample = sub.head(sample_per_cluster)\n",
    "\n",
    "        examples = \"\\n\".join(\n",
    "            _row_text(r, text_cols) for _, r in sub_sample.iterrows()\n",
    "        )\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are assigned to invent a concise, human‑readable category name\n",
    "for a cluster of data records.  Below are example rows from one cluster;\n",
    "each line shows selected fields in \"key=value\" format.\n",
    "\n",
    "Example rows:\n",
    "{examples}\n",
    "\n",
    "Provide ONE short category name (2–4 words max) that describes these rows.\n",
    "Reply with ONLY the name, no bullet points, no extra text.\n",
    "\"\"\"\n",
    "        category = llm.predict(prompt).strip().strip('\"').strip(\"'\")\n",
    "        mapping[label] = category or \"unknown\"\n",
    "\n",
    "    # attach back\n",
    "    df_out = df.copy()\n",
    "    df_out[\"generated_category\"] = df_out[cluster_col].map(mapping).fillna(\"unknown\")\n",
    "    return df_out, mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ddc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 'noise', 0: 'Traffic Signal Nodes', 1: 'Almien Coastlines Nodes', 2: 'Untagged Node Objects', 3: 'PGS Nodes (Inaccurate)'}\n",
      "           id  type tags        lat       lon  cluster_label  \\\n",
      "0      123379  node   {}  51.200308  4.377739              2   \n",
      "1      123380  node   {}  51.199611  4.380116              2   \n",
      "2      123381  node   {}  51.199706  4.381602              2   \n",
      "3      123382  node   {}  51.199627  4.383552              2   \n",
      "4      123383  node   {}  51.199074  4.384953              2   \n",
      "..        ...   ...  ...        ...       ...            ...   \n",
      "995  26020665  node   {}  51.188954  4.404348              2   \n",
      "996  26020667  node   {}  51.189494  4.404904              2   \n",
      "997  26020670  node   {}  51.190460  4.405931              2   \n",
      "998  26020673  node   {}  51.190796  4.406289              2   \n",
      "999  26020675  node   {}  51.191706  4.407141              2   \n",
      "\n",
      "        generated_category  \n",
      "0    Untagged Node Objects  \n",
      "1    Untagged Node Objects  \n",
      "2    Untagged Node Objects  \n",
      "3    Untagged Node Objects  \n",
      "4    Untagged Node Objects  \n",
      "..                     ...  \n",
      "995  Untagged Node Objects  \n",
      "996  Untagged Node Objects  \n",
      "997  Untagged Node Objects  \n",
      "998  Untagged Node Objects  \n",
      "999  Untagged Node Objects  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df_named, cluster_to_name = name_clusters_via_llm(\n",
    "    clustered,\n",
    "    cluster_col=\"cluster_label\",\n",
    "    text_cols=classification_columns,       # columns you clustered on\n",
    "    sample_per_cluster=1000           # cap rows per cluster sent to LLM\n",
    ")\n",
    "\n",
    "print(cluster_to_name)\n",
    "print(df_named)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3decf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>tags</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>generated_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>636356</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.200304</td>\n",
       "      <td>4.390010</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>18277791</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals', 'crossing': 'tr...</td>\n",
       "      <td>51.265209</td>\n",
       "      <td>4.463029</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>25912830</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.192710</td>\n",
       "      <td>4.446858</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>25913046</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.199916</td>\n",
       "      <td>4.450123</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>25913319</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.197214</td>\n",
       "      <td>4.442322</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>25914706</td>\n",
       "      <td>node</td>\n",
       "      <td>{'kerb': 'lowered', 'highway': 'crossing', 'cr...</td>\n",
       "      <td>51.192829</td>\n",
       "      <td>4.446957</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>25914761</td>\n",
       "      <td>node</td>\n",
       "      <td>{'traffic_calming': 'yes'}</td>\n",
       "      <td>51.190652</td>\n",
       "      <td>4.449214</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>25914770</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'marked'}</td>\n",
       "      <td>51.189798</td>\n",
       "      <td>4.449170</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>25915124</td>\n",
       "      <td>node</td>\n",
       "      <td>{'kerb': 'lowered', 'highway': 'crossing', 'cr...</td>\n",
       "      <td>51.197275</td>\n",
       "      <td>4.442461</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>25915127</td>\n",
       "      <td>node</td>\n",
       "      <td>{'kerb': 'lowered', 'highway': 'crossing', 'cr...</td>\n",
       "      <td>51.197196</td>\n",
       "      <td>4.442535</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>25921640</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.192845</td>\n",
       "      <td>4.437550</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>25924668</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.191787</td>\n",
       "      <td>4.423075</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>25924721</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.200081</td>\n",
       "      <td>4.439214</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>25944072</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.190643</td>\n",
       "      <td>4.423921</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>25944073</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.190749</td>\n",
       "      <td>4.424176</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>25944157</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.180100</td>\n",
       "      <td>4.433077</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>25944158</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.179982</td>\n",
       "      <td>4.432863</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>25944159</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.179904</td>\n",
       "      <td>4.433268</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>25944160</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.179784</td>\n",
       "      <td>4.433032</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>25944267</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.188142</td>\n",
       "      <td>4.423467</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>25944268</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.188312</td>\n",
       "      <td>4.423428</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>25944272</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.188331</td>\n",
       "      <td>4.423145</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>25944275</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.188150</td>\n",
       "      <td>4.423189</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>25944296</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'marked', ...</td>\n",
       "      <td>51.182847</td>\n",
       "      <td>4.424056</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>25946274</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.192921</td>\n",
       "      <td>4.437164</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>25946326</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.201481</td>\n",
       "      <td>4.435040</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>25946340</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'crossing', 'crossing': 'traffic_s...</td>\n",
       "      <td>51.201537</td>\n",
       "      <td>4.434876</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>25946699</td>\n",
       "      <td>node</td>\n",
       "      <td>{'bicycle': 'yes', 'highway': 'crossing', 'cro...</td>\n",
       "      <td>51.184663</td>\n",
       "      <td>4.418039</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>25946856</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.189529</td>\n",
       "      <td>4.425196</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>25946861</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals', 'traffic_signal...</td>\n",
       "      <td>51.189616</td>\n",
       "      <td>4.425094</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>25947723</td>\n",
       "      <td>node</td>\n",
       "      <td>{'highway': 'traffic_signals'}</td>\n",
       "      <td>51.192481</td>\n",
       "      <td>4.412379</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic Signal Nodes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  type                                               tags  \\\n",
       "33     636356  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "123  18277791  node  {'highway': 'traffic_signals', 'crossing': 'tr...   \n",
       "526  25912830  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "533  25913046  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "556  25913319  node                     {'highway': 'traffic_signals'}   \n",
       "573  25914706  node  {'kerb': 'lowered', 'highway': 'crossing', 'cr...   \n",
       "579  25914761  node                         {'traffic_calming': 'yes'}   \n",
       "583  25914770  node      {'highway': 'crossing', 'crossing': 'marked'}   \n",
       "620  25915124  node  {'kerb': 'lowered', 'highway': 'crossing', 'cr...   \n",
       "621  25915127  node  {'kerb': 'lowered', 'highway': 'crossing', 'cr...   \n",
       "662  25921640  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "767  25924668  node                     {'highway': 'traffic_signals'}   \n",
       "777  25924721  node                     {'highway': 'traffic_signals'}   \n",
       "827  25944072  node                     {'highway': 'traffic_signals'}   \n",
       "828  25944073  node                     {'highway': 'traffic_signals'}   \n",
       "840  25944157  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "841  25944158  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "842  25944159  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "843  25944160  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "855  25944267  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "856  25944268  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "857  25944272  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "858  25944275  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "865  25944296  node  {'highway': 'crossing', 'crossing': 'marked', ...   \n",
       "887  25946274  node                     {'highway': 'traffic_signals'}   \n",
       "898  25946326  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "900  25946340  node  {'highway': 'crossing', 'crossing': 'traffic_s...   \n",
       "925  25946699  node  {'bicycle': 'yes', 'highway': 'crossing', 'cro...   \n",
       "929  25946856  node                     {'highway': 'traffic_signals'}   \n",
       "930  25946861  node  {'highway': 'traffic_signals', 'traffic_signal...   \n",
       "954  25947723  node                     {'highway': 'traffic_signals'}   \n",
       "\n",
       "           lat       lon  cluster_label    generated_category  \n",
       "33   51.200304  4.390010              0  Traffic Signal Nodes  \n",
       "123  51.265209  4.463029              0  Traffic Signal Nodes  \n",
       "526  51.192710  4.446858              0  Traffic Signal Nodes  \n",
       "533  51.199916  4.450123              0  Traffic Signal Nodes  \n",
       "556  51.197214  4.442322              0  Traffic Signal Nodes  \n",
       "573  51.192829  4.446957              0  Traffic Signal Nodes  \n",
       "579  51.190652  4.449214              0  Traffic Signal Nodes  \n",
       "583  51.189798  4.449170              0  Traffic Signal Nodes  \n",
       "620  51.197275  4.442461              0  Traffic Signal Nodes  \n",
       "621  51.197196  4.442535              0  Traffic Signal Nodes  \n",
       "662  51.192845  4.437550              0  Traffic Signal Nodes  \n",
       "767  51.191787  4.423075              0  Traffic Signal Nodes  \n",
       "777  51.200081  4.439214              0  Traffic Signal Nodes  \n",
       "827  51.190643  4.423921              0  Traffic Signal Nodes  \n",
       "828  51.190749  4.424176              0  Traffic Signal Nodes  \n",
       "840  51.180100  4.433077              0  Traffic Signal Nodes  \n",
       "841  51.179982  4.432863              0  Traffic Signal Nodes  \n",
       "842  51.179904  4.433268              0  Traffic Signal Nodes  \n",
       "843  51.179784  4.433032              0  Traffic Signal Nodes  \n",
       "855  51.188142  4.423467              0  Traffic Signal Nodes  \n",
       "856  51.188312  4.423428              0  Traffic Signal Nodes  \n",
       "857  51.188331  4.423145              0  Traffic Signal Nodes  \n",
       "858  51.188150  4.423189              0  Traffic Signal Nodes  \n",
       "865  51.182847  4.424056              0  Traffic Signal Nodes  \n",
       "887  51.192921  4.437164              0  Traffic Signal Nodes  \n",
       "898  51.201481  4.435040              0  Traffic Signal Nodes  \n",
       "900  51.201537  4.434876              0  Traffic Signal Nodes  \n",
       "925  51.184663  4.418039              0  Traffic Signal Nodes  \n",
       "929  51.189529  4.425196              0  Traffic Signal Nodes  \n",
       "930  51.189616  4.425094              0  Traffic Signal Nodes  \n",
       "954  51.192481  4.412379              0  Traffic Signal Nodes  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_named.loc[df_named['generated_category'] == 'Traffic Signal Nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03c97233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "# --------------------------- helpers ---------------------------------\n",
    "def _looks_like_json(val) -> bool:\n",
    "    \"\"\"True if val is a dict or a JSON‑parsable string.\"\"\"\n",
    "    if isinstance(val, dict):\n",
    "        return True\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            obj = json.loads(val)\n",
    "            return isinstance(obj, dict)\n",
    "        except Exception:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "def _auto_json_columns(df: pd.DataFrame, sample: int = 50) -> List[str]:\n",
    "    \"\"\"Return column names whose sample values are mostly dicts / JSON strings.\"\"\"\n",
    "    json_cols = []\n",
    "    for col in df.columns:\n",
    "        sample_vals = df[col].dropna().head(sample)\n",
    "        if sample_vals.empty:\n",
    "            continue\n",
    "        pct_json = sample_vals.map(_looks_like_json).mean()\n",
    "        if pct_json > 0.5:          # >50 % of sampled rows look like JSON\n",
    "            json_cols.append(col)\n",
    "    return json_cols\n",
    "\n",
    "def _flatten_json_series(s: pd.Series, prefix: str, sep=\"_\") -> pd.DataFrame:\n",
    "    \"\"\"Recursively flatten a JSON/dict series into scalar columns.\"\"\"\n",
    "    def flat(v, px=\"\"):\n",
    "        if isinstance(v, str):\n",
    "            try: v = json.loads(v)\n",
    "            except: return {px[:-1]: v}\n",
    "        if isinstance(v, dict):\n",
    "            out = {}\n",
    "            for k, val in v.items():\n",
    "                out.update(flat(val, f\"{px}{k}{sep}\"))\n",
    "            return out\n",
    "        return {px[:-1]: v}\n",
    "    return pd.json_normalize(s.map(lambda x: flat(x, f\"{prefix}{sep}\")))\n",
    "\n",
    "# ------------------- summarizer with auto‑detection -------------------\n",
    "def summarize_category_with_llm(\n",
    "    df: pd.DataFrame,\n",
    "    category: str,\n",
    "    llm,\n",
    "    id_col: str                = \"id\",\n",
    "    auto_sample: int           = 50         # rows per column to test for JSON\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    1) Filters df to `category`\n",
    "    2) Auto‑detects JSON‑like columns and flattens them\n",
    "    3) Computes per‑column stats\n",
    "    4) Returns stats + LLM narrative\n",
    "    \"\"\"\n",
    "    sub = df[df[\"generated_category\"] == category].copy()\n",
    "    if sub.empty:\n",
    "        return {\"summary\": {}, \"narrative\": f\"No records for '{category}'.\"}\n",
    "\n",
    "    # 1⃣  auto‑detect and flatten all JSON‑ish columns\n",
    "    json_cols = _auto_json_columns(sub, sample=auto_sample)\n",
    "    flat_parts = [sub]\n",
    "    for jc in json_cols:\n",
    "        flat_parts.append(_flatten_json_series(sub[jc], jc))\n",
    "    wide = pd.concat(flat_parts, axis=1).drop(columns=json_cols)\n",
    "\n",
    "    # 2⃣  quick type-aware stats\n",
    "    summary = {\"category\": category, \"n_rows\": len(wide), \"columns\": {}}\n",
    "    for col in wide.columns:\n",
    "        if col in (\"assigned_category\", \"geometry\"):\n",
    "            continue\n",
    "        ser = wide[col].dropna()\n",
    "        if ser.empty:\n",
    "            summary[\"columns\"][col] = {\"all_null\": True}\n",
    "            continue\n",
    "        if ser.dtype.kind in \"if\":\n",
    "            summary[\"columns\"][col] = {\n",
    "                \"type\": \"numeric\",\n",
    "                \"min\": ser.min(),\n",
    "                \"max\": ser.max(),\n",
    "                \"mean\": ser.mean(),\n",
    "                \"p50\": ser.quantile(.5),\n",
    "                \"p95\": ser.quantile(.95),\n",
    "            }\n",
    "        elif ser.dtype == bool or ser.isin([0, 1]).all():\n",
    "            summary[\"columns\"][col] = {\n",
    "                \"type\": \"boolean\",\n",
    "                \"pct_true\": float(ser.mean()),\n",
    "            }\n",
    "        else:\n",
    "            top = ser.value_counts().head(5)\n",
    "            summary[\"columns\"][col] = {\n",
    "                \"type\": \"categorical\",\n",
    "                \"distinct\": int(ser.nunique()),\n",
    "                \"top_values\": top.to_dict(),\n",
    "            }\n",
    "\n",
    "    # 3⃣  Ask LLM for narrative\n",
    "    prompt = f\"\"\"\n",
    "You are a data analyst. Summarize these statistics for the category \"{category}\"\n",
    "in 3‑4 sentences, highlighting notable patterns in markdown format.\n",
    "\n",
    "Stats JSON:\n",
    "{json.dumps(summary, indent=2)}\n",
    "\"\"\"\n",
    "    narrative = llm.predict(prompt).strip()\n",
    "\n",
    "    return {\"summary\": summary, \"narrative\": narrative}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da678644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 62 traffic signal nodes, primarily located around latitude 51.19 and longitude 4.43. The nodes are overwhelmingly tagged as \"node\" type, and the `cluster_label` is consistently 0.  Most nodes are tagged with `highway=crossing` or `highway=traffic_signals`, and many crossings are further specified as `traffic_signals` or `marked`.  A small subset of nodes have additional tags related to accessibility features like tactile paving, sound signals, and button operation.\n"
     ]
    }
   ],
   "source": [
    "result = summarize_category_with_llm(df_named, \"Traffic Signal Nodes\", gemini)\n",
    "print(result['narrative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b878ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects.postgresql import (\n",
    "    BIGINT, INTEGER, DOUBLE_PRECISION, TEXT, BOOLEAN, JSONB, ARRAY\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────\n",
    "# CONFIG: supply via env var or pass in directly\n",
    "# ─────────────────────────────────────────────────────────\n",
    "DEFAULT_DB_URL = os.getenv(\n",
    "    \"DB_URL\",\n",
    "    \"postgresql+psycopg2://devuser:devpassword@localhost:5433/devdb\"\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────\n",
    "# dtype helper  →  map pandas dtypes to Postgres types\n",
    "# ─────────────────────────────────────────────────────────\n",
    "def _infer_pg_dtype(series: pd.Series):\n",
    "    if pd.api.types.is_integer_dtype(series):\n",
    "        return BIGINT \n",
    "    if pd.api.types.is_float_dtype(series):\n",
    "        return DOUBLE_PRECISION\n",
    "    if pd.api.types.is_bool_dtype(series):\n",
    "        return BOOLEAN\n",
    "    if pd.api.types.is_object_dtype(series):\n",
    "        # crude checks for JSON or list\n",
    "        sample = series.dropna().head(1)\n",
    "        if not sample.empty and isinstance(sample.iloc[0], (dict, list)):\n",
    "            return JSONB if isinstance(sample.iloc[0], dict) else ARRAY(TEXT)\n",
    "        return TEXT\n",
    "    return TEXT  # fallback\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────\n",
    "# main writer\n",
    "# ─────────────────────────────────────────────────────────\n",
    "def write_df_to_postgres(\n",
    "    df: pd.DataFrame,\n",
    "    table_name: str,\n",
    "    db_url: str = DEFAULT_DB_URL,\n",
    "    schema: Optional[str] = None,\n",
    "    if_exists: str = \"replace\",   # \"append\" or \"replace\"\n",
    "    chunksize: int = 10_000\n",
    ") -> None:\n",
    "    engine = create_engine(db_url)\n",
    "\n",
    "    # Build dtype mapping\n",
    "    dtype_map: Dict[str, Any] = {\n",
    "        col: _infer_pg_dtype(df[col]) for col in df.columns\n",
    "    }\n",
    "\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        schema=schema,\n",
    "        if_exists=if_exists,\n",
    "        index=False,\n",
    "        dtype=dtype_map,\n",
    "        method=\"multi\",\n",
    "        chunksize=chunksize\n",
    "    )\n",
    "    print(f\"✅  Wrote {len(df)} rows → {schema+'.' if schema else ''}{table_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acede605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Wrote 1000 rows → nodes_categorized\n"
     ]
    }
   ],
   "source": [
    "new_table_name = \"nodes_categorized\"\n",
    "\n",
    "write_df_to_postgres(df_named, table_name=\"nodes_categorized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, re, json\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_openai import ChatOpenAI                 # ← swap for Gemini if you prefer\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ──────────────────────── CONFIG ───────────────────────────\n",
    "DB_URL   = os.getenv(\"DB_URL\", \"postgresql+psycopg2://devuser:devpassword@localhost:5433/devdb\")\n",
    "TABLE    = \"nodes_categorized\"\n",
    "CAT_COL  = \"generated_category\"\n",
    "\n",
    "llm      = gemini\n",
    "db       = SQLDatabase.from_uri(DB_URL)\n",
    "\n",
    "\n",
    "\n",
    "# ─────── helper #2: list categories (for your UI) ───────\n",
    "def list_categories() -> List[str]:\n",
    "    sql = text(f\"SELECT DISTINCT {CAT_COL} FROM {TABLE} ORDER BY 1;\")\n",
    "    with create_engine(DB_URL).connect() as conn:\n",
    "        return [r[0] for r in conn.execute(sql)]\n",
    "\n",
    "# ──────────────────  MEMORY (keeps current category) ──────────────────\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
    "                                  return_messages=True,\n",
    "                                  ai_prefix=\"Assistant\")\n",
    "\n",
    "# ──────────────────  TOOL 1  – choose a category  ─────────────────────\n",
    "def _choose(cat: str) -> str:\n",
    "    # save chosen category in memory.buffer\n",
    "    memory.buffer = cat\n",
    "    return summarize_category_markdown(cat)\n",
    "\n",
    "choose_tool = Tool(\n",
    "    name=\"choose_category\",\n",
    "    func=_choose,\n",
    "    description=\"Select a category by exact name and get a markdown summary.\"\n",
    ")\n",
    "\n",
    "# ──────────────────  TOOL 2 – text‑to‑SQL question  ───────────────────\n",
    "sql_chain = create_sql_query_chain(llm, db)\n",
    "\n",
    "def _answer_sql(question: str) -> str:\n",
    "    cat = getattr(memory, \"buffer\", None)\n",
    "    if not cat:\n",
    "        return (\"No category chosen. First call `choose_category` with one of: \"\n",
    "                + \", \".join(list_categories()))\n",
    "    base_sql = sql_chain.run(\n",
    "        f\"{question}\\nOnly use table `{TABLE}` and include column names.\" )\n",
    "    # inject WHERE so it only scans current category\n",
    "    final_sql = ( base_sql.rstrip(\";\") + f\" WHERE {CAT_COL} = '{cat}';\"\n",
    "                  if \"WHERE\" not in base_sql.upper()\n",
    "                  else re.sub(r\"(?i)\\bWHERE\\b\",\n",
    "                              f\"WHERE {CAT_COL} = '{cat}' AND \", base_sql, 1) )\n",
    "    # execute & pretty‑print\n",
    "    with create_engine(DB_URL).connect() as conn:\n",
    "        rows = conn.execute(text(final_sql)).fetchmany(25)\n",
    "    return \"```json\\n\" + json.dumps([dict(r) for r in rows], indent=2) + \"\\n```\"\n",
    "\n",
    "ask_tool = Tool(\n",
    "    name=\"ask_sql\",\n",
    "    func=_answer_sql,\n",
    "    description=\"Free‑form question about the CURRENT category; returns JSON rows.\"\n",
    ")\n",
    "\n",
    "# ──────────────────  AGENT  ───────────────────────────────\n",
    "agent = initialize_agent(\n",
    "    tools    =[choose_tool, ask_tool],\n",
    "    llm      = llm,\n",
    "    agent    = AgentType.OPENAI_FUNCTIONS,        # auto tool‑calling\n",
    "    memory   = memory,\n",
    "    verbose  = False,\n",
    ")\n",
    "\n",
    "# ──────────────────  CLI demo  ────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Available categories:\")\n",
    "    print(\", \".join(list_categories()))\n",
    "    print(\"\\nUse choose_category(\\\"<name>\\\") then ask_sql(\\\"…?\\\")\\n\")\n",
    "\n",
    "    while True:\n",
    "        user = input(\">> \")\n",
    "        if user.lower().strip() in {\"quit\", \"exit\"}: break\n",
    "        print(agent.run(user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n",
    "\n",
    "# ───────────────────────── helpers ─────────────────────────\n",
    "def _looks_like_json_second(v) -> bool:\n",
    "    if isinstance(v, dict):\n",
    "        return True\n",
    "    if isinstance(v, str):\n",
    "        try:\n",
    "            return isinstance(json.loads(v), dict)\n",
    "        except Exception:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "def _auto_json_cols_second(df: pd.DataFrame, sample: int = 50) -> List[str]:\n",
    "    \"\"\"Detect columns that hold dicts / JSON strings.\"\"\"\n",
    "    out = []\n",
    "    for c in df.columns:\n",
    "        s = df[c].dropna().head(sample)\n",
    "        if not s.empty and s.map(_looks_like_json).mean() > 0.5:\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def _flatten_json_series_second(s: pd.Series, prefix: str, sep: str = \".\") -> pd.DataFrame:\n",
    "    \"\"\"Flatten dict / JSON strings into dot‑path columns.\"\"\"\n",
    "    def flat(v, px=\"\"):\n",
    "        if isinstance(v, str):\n",
    "            try: v = json.loads(v)\n",
    "            except: return {px[:-1]: v}\n",
    "        if isinstance(v, dict):\n",
    "            out = {}\n",
    "            for k, val in v.items():\n",
    "                out.update(flat(val, f\"{px}{k}{sep}\"))\n",
    "            return out\n",
    "        return {px[:-1]: v}\n",
    "    return pd.json_normalize(s.map(lambda x: flat(x, f\"{prefix}{sep}\")))\n",
    "\n",
    "def _infer_type_second(series: pd.Series) -> str:\n",
    "    \"\"\"Return a simple type label suitable for SQL or prompt.\"\"\"\n",
    "    if pd.api.types.is_integer_dtype(series):\n",
    "        return \"integer\"\n",
    "    if pd.api.types.is_float_dtype(series):\n",
    "        return \"float\"\n",
    "    if pd.api.types.is_bool_dtype(series):\n",
    "        return \"boolean\"\n",
    "    return \"text\"\n",
    "\n",
    "# ───────────────────────── main builder ─────────────────────\n",
    "def build_category_schema(\n",
    "    df: pd.DataFrame,\n",
    "    category: str,\n",
    "    cat_col: str = \"generated_category\",\n",
    "    sample_rows: int = 10_000\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Returns {column_or_json_key: datatype} for the chosen category.\n",
    "    JSON keys are flatted with dot‑notation (e.g. tags.highway).\n",
    "    \"\"\"\n",
    "    sub = df[df[cat_col] == category]\n",
    "    if sub.empty:\n",
    "        return {}\n",
    "\n",
    "    # (optional) sample for speed\n",
    "    if len(sub) > sample_rows:\n",
    "        sub = sub.sample(sample_rows, random_state=42)\n",
    "\n",
    "    json_cols = _auto_json_cols(sub)\n",
    "    parts     = [sub]\n",
    "\n",
    "    for jc in json_cols:\n",
    "        parts.append(_flatten_json_series(sub[jc], prefix=jc))\n",
    "\n",
    "    wide = pd.concat(parts, axis=1).drop(columns=json_cols)\n",
    "\n",
    "    schema = {\n",
    "        col: _infer_type(wide[col].dropna())\n",
    "        for col in wide.columns\n",
    "    }\n",
    "    return schema\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8605ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"nodes_with_category.parquet\")\n",
    "schema = build_category_schema(df, category=\"Speed Camera\")\n",
    "print(json.dumps(schema, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
